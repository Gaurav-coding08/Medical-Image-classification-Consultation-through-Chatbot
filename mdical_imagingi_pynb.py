# -*- coding: utf-8 -*-
"""mdical imagingi.pynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MlmDtlaBPzhQJNPatQ164YTj5L5U-N1R
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf 
from tensorflow import keras 
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Activation,Dense,Flatten,BatchNormalization,Conv2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix
import itertools
import os
import shutil
import random
import glob
import matplotlib.pyplot as plt 
import warnings
warnings.simplefilter(action='ignore',category=FutureWarning)
# %matplotlib inline

from tensorflow.keras.layers import MaxPool2D

train_path='/content/drive/MyDrive/mri brain/Training'
test_path ='/content/drive/MyDrive/mri brain/Testing' 
val_path = '/content/drive/MyDrive/mri brain/validation'

train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_v3.preprocess_input).flow_from_directory(directory=train_path,target_size=(224,224),classes=['glioma','meningioma','notumor','pituitary'],batch_size=64)
test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_v3.preprocess_input).flow_from_directory(directory=test_path,target_size=(224,224),classes=['glioma','meningioma','notumor','pituitary'],batch_size=64,shuffle=False)
val_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_v3.preprocess_input).flow_from_directory(directory=val_path,target_size=(224,224),classes=['glioma','meningioma','notumor','pituitary'],batch_size=64,shuffle=False)

base_model = tf.keras.applications.InceptionV3(input_shape = (224, 224, 3),pooling=None, include_top = False, weights = 'imagenet')

del model

sum=0
a=0
l=0

for a in base_model.layers:
   sum=sum+1
print(sum)

for a in base_model.layers[:271]:
    a.trainable = False

for l in base_model.layers:
    print(l.name, l.trainable)
    sum=sum+1
print(sum)

from tensorflow.keras.optimizers import Adam
from tensorflow.keras import layers
x = layers.Flatten()(base_model.output)
x = layers.Dense(1024, activation='relu')(x)
x = layers.Dropout(0.2)(x)

# Add a final softmax layer with 4 node for classification output
x = layers.Dense(4, activation='softmax')(x)

model = tf.keras.models.Model(base_model.input, x)

model.compile(optimizer = Adam(lr=0.0001), loss = 'categorical_crossentropy', metrics = ['acc'])

model.fit(train_batches,validation_data=val_batches,steps_per_epoch=83,epochs=5)/3rd inception

predictions=model.predict(x=test_batches,verbose=0)

cm = confusion_matrix(y_true=test_batches.classes,y_pred=np.argmax(predictions,axis=-1))

from sklearn.datasets import make_classification
from sklearn.metrics import plot_confusion_matrix

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

cm_plot_labels = ['glioma','meningioma','notumor','pituitary']/3rd inception
plot_confusion_matrix(cm=cm,classes=cm_plot_labels,title='Confusion matrix')

import torch

modeleffb0first=model

path = '/content/drive/My Drive/modelincepfirst' 
torch.save(model,path)

path = '/content/drive/My Drive/modeleffb0first'
model30=torch.load(path)

// testing on custom

from skimage.io import imread
img = imread('/content/gaurav_burj khalifa.jpg')

from skimage.transform import resize

img= resize(img,(224,224,3))

import cv2
image = cv2.imread('/content/gaurav_atlantis.jpg')
  
# Window name in which image is displayed
window_name = 'image'
  
# Using cv2.imshow() method 
# Displaying the image 
cv2.imshow(window_name, image)

img=np.array(img,dtype=np.float32)
img= np.expand_dims(img,axis=0)

test_pred=model3.predict(img)
x_pred=np.argmax(test_pred,axis=-1)
print(x_pred)

y=x_pred

print(y)



y_pred=np.argmax(predictions,axis=-1)

y_pred

z=y_pred[0:5]

p=y_pred[444:449]

//CHEST XRAY



# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf 
from tensorflow import keras 
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Activation,Dense,Flatten,BatchNormalization,Conv2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix
import itertools
import os
import shutil
import random
import glob
import matplotlib.pyplot as plt 
import warnings
warnings.simplefilter(action='ignore',category=FutureWarning)
# %matplotlib inline

from tensorflow.keras.layers import MaxPool2D

train_path='/content/drive/MyDrive/chest_xray/train'
test_path ='/content/drive/MyDrive/chest_xray/test' 
val_path = '/content/drive/MyDrive/chest_xray/val'

train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input ).flow_from_directory(directory=train_path,target_size=(224,224),classes=['NORMAL','PNEUMONIA'],batch_size=64)
test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input ).flow_from_directory(directory=test_path,target_size=(224,224),classes=['NORMAL','PNEUMONIA'],batch_size=64,shuffle=False)
val_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input ).flow_from_directory(directory=val_path,target_size=(224,224),classes=['NORMAL','PNEUMONIA'],batch_size=64,shuffle=False)

base_model = tf.keras.applications.EfficientNetB3(input_shape = (224, 224, 3),pooling=None, include_top = False, weights = 'imagenet')

del x

sum=0
a=0
l=0

for a in base_model.layers:
   sum=sum+1
print(sum)

for a in base_model.layers[:345]:
    a.trainable = False

for l in base_model.layers:
    print(l.name, l.trainable)
    sum=sum+1
print(sum)

from tensorflow.keras.optimizers import Adam
from tensorflow.keras import layers
x = layers.Flatten()(base_model.output)
x = layers.Dense(1024, activation='relu')(x)
x = layers.Dropout(0.2)(x)

# Add a final softmax layer with 4 node for classification output
x = layers.Dense(2, activation='softmax')(x)

model = tf.keras.models.Model(base_model.input, x)

model.compile(optimizer = Adam(lr=0.0001), loss = 'categorical_crossentropy', metrics = ['acc'])

del model

model.fit(train_batches,validation_data=val_batches,steps_per_epoch=80,epochs=5)

predictions=model.predict(x=test_batches,verbose=0)

predictions

cm = confusion_matrix(y_true=test_batches.classes,y_pred=np.argmax(predictions,axis=-1))

from sklearn.datasets import make_classification
from sklearn.metrics import plot_confusion_matrix

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

cm_plot_labels=['NORMAL','PNEUMONIA']
plot_confusion_matrix(cm=cm,classes=cm_plot_labels,title='Confusion matrix')

import torch

modeleffb0first=model

path='/content/drive/My Drive/modelEFFNETB3chestfirst' 
torch.save(model,path)



//lung image histopathalogical images

del x_pred



# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf 
from tensorflow import keras 
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Activation,Dense,Flatten,BatchNormalization,Conv2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix
import itertools
import os
import shutil
import random
import glob
import matplotlib.pyplot as plt 
import warnings
warnings.simplefilter(action='ignore',category=FutureWarning)
# %matplotlib inline

from tensorflow.keras.layers import MaxPool2D

train_path='/content/drive/MyDrive/lung_image_sets/training'
test_path ='/content/drive/MyDrive/lung_image_sets/testing' 
val_path = '/content/drive/MyDrive/lung_image_sets/validation'

train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input).flow_from_directory(directory=train_path,target_size=(224,224),classes=['lung_aca','lung_n','lung_scc'],batch_size=64)
test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input).flow_from_directory(directory=test_path,target_size=(224,224),classes=['lung_aca','lung_n','lung_scc'],batch_size=64,shuffle=False)
val_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input).flow_from_directory(directory=val_path,target_size=(224,224),classes=['lung_aca','lung_n','lung_scc'],batch_size=64,shuffle=False)

base_model = tf.keras.applications.EfficientNetB3(input_shape = (224, 224, 3),pooling=None, include_top = False, weights = 'imagenet')

del x

sum=0
a=0
l=0

for a in base_model.layers:
   sum=sum+1
print(sum)

for a in base_model.layers[:345]:
    a.trainable = False

for l in base_model.layers:
    print(l.name, l.trainable)
    sum=sum+1
print(sum)

from tensorflow.keras.optimizers import Adam
from tensorflow.keras import layers
x = layers.Flatten()(base_model.output)
x = layers.Dense(1024, activation='relu')(x)
x = layers.Dropout(0.2)(x)

# Add a final softmax layer with 3 node for classification output
x = layers.Dense(3, activation='softmax')(x)

model = tf.keras.models.Model(base_model.input, x)

model.compile(optimizer = Adam(lr=0.0001), loss = 'categorical_crossentropy', metrics = ['acc'])

del x

from pandas.tseries.offsets import Second
model.fit(train_batches,validation_data=val_batches,steps_per_epoch=92,epochs=5)//third efnet b3 lung

predictions=model.predict(x=test_batches,verbose=0)

cm = confusion_matrix(y_true=test_batches.classes,y_pred=np.argmax(predictions,axis=-1))

from sklearn.datasets import make_classification
from sklearn.metrics import plot_confusion_matrix

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

cm_plot_labels = ['lung_aca','lung_n','lung_scc'] 
plot_confusion_matrix(cm=cm,classes=cm_plot_labels,title='Confusion matrix')

import torch

path='/content/drive/My Drive/modeleffnetb3LUNGthird' 
torch.save(model,path)

path = '/content/drive/MyDrive/MRI MODELS/modeleffb1first'
modelmri=torch.load(path)

path2 = '/content/drive/MyDrive/chest_models/modelEFFNETB0chestsecond'
modelchest=torch.load(path)

path3 = '/content/drive/MyDrive/lung images models/modeleffnetb3LUNGthird'
modellung=torch.load(path)

from skimage.transform import resize  
import cv2

print("WELCOME TO MEDICAL IMAGING SOFTWARE AND CONSULTATION \n")
print("WE ARE HERE TO IDENTIFY YOUR DISEASE AND GIVE CONSULATION \n")
print("PRESS 1 IF YOU WANT TO SCAN YOUR BRAIN MRI ")
print("PRESS 2 IF YOU WANT TO SCAN YOUR CHEST XRAY")
print("PRESS 3 IF YOU WANT TO SCAN YOUR HISTOPATHOLOGICAL SAMPLE")
x=input()
if x=='1':
  from skimage.io import imread
  y=input("paste your image link")
  img = imread(y)
  img= resize(img,(224,224,3))
  img=np.array(img,dtype=np.float32)
  img= np.expand_dims(img,axis=0)
  test_pred=modelmri.predict(img)
  x_pred=np.argmax(test_pred,axis=-1)
  x=x_pred
  print(x_pred)
  if (x_pred==0):
    print("YOU ARE DETECTED WITH GLIOMA\n")
  elif (x_pred==1):
    print("YOU ARE DETECTED WITH MANIGLIOMA\n")
  elif (x_pred==2):
    print("YOU ARE DETECTED WITH NO TUMOR\n")
  else:
    print("YOU ARE DETECTED WITH PITUITARY\n")
elif x=='2':
  from skimage.io import imread
  y=input("please paste your chest image or file path")
  img = imread(y)
  img= resize(img,(224,224,3))
  img=np.array(img,dtype=np.float32)
  img= np.expand_dims(img,axis=0)
  test_pred=modelchest.predict(img)
  x_pred=np.argmax(test_pred,axis=-1)
  print(x_pred)
  x=x_pred
  if (x == 0):
    print("YOU ARE ABSOLUTELY NORMAL\n")
  else:
    print("YOU ARE DETECTED WITH PNEUMONIA\n")
elif x=='3':
  from skimage.io import imread
  y=input("please paste your image or file path")
  img = imread(y)
  img= resize(img,(224,224,3))
  img=np.array(img,dtype=np.float32)
  img= np.expand_dims(img,axis=0)
  test_pred=modellung.predict(img)
  x_pred=np.argmax(test_pred,axis=-1)
  print(x_pred)
  x=x_pred
  if  (x_pred==0):
    print("YOU ARE DETECTED WITH LUNG_ACA\n")
  elif (x_pred==1):
    print("YOUR LUNG IMAGE IS BENIGN\n")
  elif (x_pred==2):
    print("YOU ARE DETECTED WITH LUNG SCC\n")
print("thanks")



x

from skimage.io import imread
img = imread('/content/gaurav_burj khalifa.jpg')



img= resize(img,(224,224,3))

import cv2
image = cv2.imread('/content/gaurav_atlantis.jpg')
  
# Window name in which image is displayed
window_name = 'image'
  
# Using cv2.imshow() method 
# Displaying the image 
cv2.imshow(window_name, image)

img=np.array(img,dtype=np.float32)
img= np.expand_dims(img,axis=0)

test_pred=model3.predict(img)
x_pred=np.argmax(test_pred,axis=-1)
print(x_pred)

import re 
import nltk
import string
import random

f=open('/content/chatbot dataset.txt','r',errors = 'ignore')
raw_doc=f.read()

raw_doc

raw_doc=raw_doc.lower()
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')

sentence_tokens=nltk.sent_tokenize(raw_doc)
word_tokens=nltk.word_tokenize(raw_doc)

lemmer=nltk.stem.WordNetLemmatizer()
def Lemtokens(tokens):
  return [lemmer.lemmatize(token) for token in tokens]
remove_punc_dict=dict((ord(punct),None) for punct in string.punctuation)
def LemNormalize(text):
  return Lemtokens(nltk.word_tokenize(text.lower().translate(remove_punc_dict)))

greet_inputs=('hello ','hi')
greet_responses=('hi i am a medical bot who can give knowledge about pneumonia,lung cancer and brain tumors','hey i am a medical bot who can give knowledge about pneumonia,lung cancer and brain tumors')
def greet(sentence):
  for word in sentence.split():
    if word.lower() in greet_inputs:
      return random.choice(greet_responses)

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def response(user_response):
  robal_response= ''
  TfidfVec = TfidfVectorizer(tokenizer = LemNormalize,stop_words='english')
  tfidf = TfidfVec.fit_transform(sentence_tokens)
  vals=cosine_similarity(tfidf[-1],tfidf)
  idx = vals.argsort()[0][-2]
  flat= vals.flatten()
  flat.sort()
  req_tfidf = flat[-2]
  if (req_tfidf == 0):
    robal_response = robal_response + "I am sorry.Unable to understand you"
    return robal_response
  else:
    robal_response = robal_response+ sentence_tokens[idx]
    return robal_response

from tensorflow.python import user_ops
from tensorflow.python.ops.init_ops_v2 import TruncatedNormal
flag = True
print('i am a medical bot who can give knowledge about pneumonia,lung cancer and brain tumors')
while(flag == True):
  user_response=input()
  user_response= user_response.lower()
  if(user_response !='bye'):
    if(user_response=='thank you' or user_response=='thanks'):
      flag=False
      print('Bot:You are welcome..')
    else:
     if(greet(user_response)!=None):
       print('Bot'+greet(user_response))
     else:
       sentence_tokens.append(user_response)
       word_tokens=word_tokens +nltk.word_tokenize(user_response)
       final_words = list(set(word_tokens))
       print('Bot: ',end = '')
       print(response(user_response))
       sentence_tokens.remove(user_response)
  else:
    flag=False
    print('Bot: Goodbye!')